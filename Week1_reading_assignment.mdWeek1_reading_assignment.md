 I pick the article **“[Which Covid-19 Data Can You Trust?](https://hbr.org/2020/05/which-covid-19-data-can-you-trust)”** written by Satchit Balsari, Caroline Buckee, and Tarun Khanna from the Harvard Business Review. According to this article, some Covid-19 data, including national metrics of physical distancing and contact tracing data, are over-aggregated or too limited as well as provided by lack of expertise or reliability. The authors also suggest the importance of transparency, thoughtfulness, and open platforms for data. This is because the opened data allows people, including other researchers, to review, suggest, and check the data and prevents data providers from missing information. 
 
The reason why this article speaks to me in terms of my approach to data and research is **the article raises awareness of how I should critically review data in my research project in order to avoid bias or misinterpretation.** In the article, the authors mention people tend to rely on data as one of the essential tools for understanding the effect and allocating resources in a crisis situation. Especially in the case of Covid-19, I tend to believe the data that are on the website or article without thinking if that is reliable or not because of the lack of general information for the new virus. Therefore, my own data science goal is to critically evaluate the data, like whether the data is too broad or specific, before using it for my research project to increase the reliability of my research.  
